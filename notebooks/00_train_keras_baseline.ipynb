{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afraid-webster",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "every-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "from model.vgg19 import VGG19\n",
    "from model.ViT import VisionTransformer\n",
    "from model.augmentation import aug_process\n",
    "from dataloader import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-quarter",
   "metadata": {},
   "source": [
    "# model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'EfficientNet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-fleet",
   "metadata": {},
   "source": [
    "# file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corrected-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_open = open('../config.json', 'r')\n",
    "config = json.load(json_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facial-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'{config[\"filepath\"][\"dataset\"]}'\n",
    "partitions_path = f'{config[\"filepath\"][\"partitions\"]}'\n",
    "output_path = f'{config[\"filepath\"][\"output\"]}'\n",
    "file_name = f\"{model_type}_{config['data']['img_size']}_keras_baseline\"\n",
    "log_dir = f\"{output_path}/logs/{file_name}\"\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "failing-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_path_list = glob.glob(f\"{partitions_path}/Test*\")\n",
    "train_txt_path_list = glob.glob(f\"{partitions_path}/Train*\")\n",
    "class_name_path = f\"{partitions_path}/ClassName.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-mileage",
   "metadata": {},
   "source": [
    "# label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unknown-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(class_name_path, 'r')\n",
    "label_name_list = f.readlines()\n",
    "label_name_list = list(map(lambda tmp_path: tmp_path[:-1].split('/', 2)[2], label_name_list))\n",
    "f.close()\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-gamma",
   "metadata": {},
   "source": [
    "# text to path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patient-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_path(txt_path_list):\n",
    "    path_list = []\n",
    "    for path in txt_path_list:\n",
    "        f = open(path, 'r')\n",
    "        path_list+=f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    path_list = list(map(lambda tmp_path: dataset_path+tmp_path[:-1], path_list))#.remove(config[\"data\"][\"exclude_list\"])\n",
    "    path_list = sorted(list(set(path_list)-set(config[\"data\"][\"exclude_list\"])))\n",
    "    label_list = list(map(lambda tmp_path: label_to_index[tmp_path.split('/', 6)[6].rsplit('/', 1)[0]], path_list))\n",
    "    return path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "insured-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list, label_list = txt_to_path(train_txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "political-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path_list, val_img_path_list,\\\n",
    "train_label_list, val_label_list = train_test_split(img_path_list, label_list,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "test_img_path_list, test_label_list = txt_to_path(test_txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bizarre-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot use same batch size as mixed float16\n",
    "tmp_dataloader = dataloader(config['data']['batch_size']//2, \n",
    "                            config['data']['img_size'],\n",
    "                            is_aug=True)\n",
    "\n",
    "train_ds = tmp_dataloader(train_img_path_list, train_label_list, shuffle_buffer=100)\n",
    "val_ds = tmp_dataloader(val_img_path_list, val_label_list, is_train=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-shell",
   "metadata": {},
   "source": [
    "# def model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minimal-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_classes = len(label_to_index)+1\n",
    "with strategy.scope():\n",
    "    if model_type=='vgg19':\n",
    "        model = VGG19(num_classes, img_size=config['data']['img_size'],)\n",
    "    if model_type=='ViT':\n",
    "        model = VisionTransformer(num_classes=num_classes, img_size=config['data']['img_size'])\n",
    "    if model_type=='EfficientNet':\n",
    "        model = tf.keras.applications.EfficientNetB3(classes=num_classes, weights=None,\n",
    "                                                     input_shape=(config['data']['img_size'],\n",
    "                                                                  config['data']['img_size'], 3))\n",
    "    \n",
    "optimizer = tfa.optimizers.RectifiedAdam(lr=config['data']['lr']/2, clipnorm=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy', metrics=['acc'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-brake",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "INFO:tensorflow:batch_all_reduce: 340 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 340 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2004/2004 [==============================] - 1118s 482ms/step - loss: 5.9815 - acc: 0.0053 - val_loss: 5.7409 - val_acc: 0.0158\n",
      "Epoch 2/8\n",
      "2004/2004 [==============================] - 955s 476ms/step - loss: 5.6326 - acc: 0.0151 - val_loss: 5.1789 - val_acc: 0.0339\n",
      "Epoch 3/8\n",
      "2004/2004 [==============================] - 955s 476ms/step - loss: 5.3086 - acc: 0.0284 - val_loss: 4.9416 - val_acc: 0.0474\n",
      "Epoch 4/8\n",
      "2004/2004 [==============================] - 954s 476ms/step - loss: 5.0700 - acc: 0.0405 - val_loss: 4.7804 - val_acc: 0.0607\n",
      "Epoch 5/8\n",
      "2004/2004 [==============================] - 951s 474ms/step - loss: 4.8438 - acc: 0.0563 - val_loss: 4.5499 - val_acc: 0.0839\n",
      "Epoch 6/8\n",
      "2004/2004 [==============================] - 953s 475ms/step - loss: 4.6751 - acc: 0.0710 - val_loss: 4.3873 - val_acc: 0.0984\n",
      "Epoch 7/8\n",
      "2004/2004 [==============================] - 953s 475ms/step - loss: 4.5329 - acc: 0.0883 - val_loss: 4.1796 - val_acc: 0.1246\n",
      "Epoch 8/8\n",
      "2004/2004 [==============================] - 953s 475ms/step - loss: 4.4004 - acc: 0.1007 - val_loss: 4.1152 - val_acc: 0.1280\n",
      "CPU times: user 10h 19min 14s, sys: 5min 14s, total: 10h 24min 29s\n",
      "Wall time: 2h 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TB = tf.keras.callbacks.TensorBoard(log_dir=f'{output_path}/logs/{file_name}',)\n",
    "RLRP = tf.keras.callbacks.ReduceLROnPlateau(factor=0.95, patience=2)\n",
    "hist = model.fit(train_ds, validation_data=val_ds,\n",
    "                 epochs=config['data']['epochs'], callbacks=[TB, RLRP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
