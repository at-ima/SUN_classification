{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liable-marketplace",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entertaining-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "from model.vgg19 import VGG19\n",
    "from model.ViT import VisionTransformer\n",
    "from model.augmentation import aug_process\n",
    "from dataloader import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-novel",
   "metadata": {},
   "source": [
    "# mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "canadian-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mixed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From /home/a_imagawa/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "if is_mixed:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-glossary",
   "metadata": {},
   "source": [
    "# model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'EfficientNet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-updating",
   "metadata": {},
   "source": [
    "# file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sorted-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_open = open('../config.json', 'r')\n",
    "config = json.load(json_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strategic-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'{config[\"filepath\"][\"dataset\"]}'\n",
    "partitions_path = f'{config[\"filepath\"][\"partitions\"]}'\n",
    "output_path = f'{config[\"filepath\"][\"output\"]}/01'\n",
    "file_name = f\"{model_type}_{config['data']['img_size']}\"\n",
    "log_dir = f\"{output_path}/logs/{file_name}\"\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "received-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_path_list = glob.glob(f\"{partitions_path}/Test*\")\n",
    "train_txt_path_list = glob.glob(f\"{partitions_path}/Train*\")\n",
    "class_name_path = f\"{partitions_path}/ClassName.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-charger",
   "metadata": {},
   "source": [
    "# label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sealed-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(class_name_path, 'r')\n",
    "label_name_list = f.readlines()\n",
    "label_name_list = list(map(lambda tmp_path: tmp_path[:-1].split('/', 2)[2], label_name_list))\n",
    "f.close()\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-clearance",
   "metadata": {},
   "source": [
    "# text to path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broken-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_path(txt_path_list):\n",
    "    path_list = []\n",
    "    for path in txt_path_list:\n",
    "        f = open(path, 'r')\n",
    "        path_list+=f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    path_list = list(map(lambda tmp_path: dataset_path+tmp_path[:-1], path_list))#.remove(config[\"data\"][\"exclude_list\"])\n",
    "    path_list = sorted(list(set(path_list)-set(config[\"data\"][\"exclude_list\"])))\n",
    "    label_list = list(map(lambda tmp_path: label_to_index[tmp_path.split('/', 6)[6].rsplit('/', 1)[0]], path_list))\n",
    "    return path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hairy-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list, label_list = txt_to_path(train_txt_path_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "domestic-wisdom",
   "metadata": {},
   "source": [
    "import imageio\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "def check(path):\n",
    "    try:\n",
    "        imageio.imwrite(path, imageio.imread(path)[..., :3])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "exclude_list = Parallel(n_jobs=-1)([delayed(check)(path) for path in tqdm.tqdm(img_path_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "circular-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path_list, val_img_path_list,\\\n",
    "train_label_list, val_label_list = train_test_split(img_path_list, label_list,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "test_img_path_list, test_label_list = txt_to_path(test_txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fancy-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataloader = dataloader(config['data']['batch_size'], config['data']['img_size'],)\n",
    "train_ds = tmp_dataloader(train_img_path_list, train_label_list, shuffle_buffer=100)\n",
    "val_ds = tmp_dataloader(val_img_path_list, val_label_list, train=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-commission",
   "metadata": {},
   "source": [
    "# def model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pharmaceutical-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_classes = len(label_to_index)+1\n",
    "with strategy.scope():\n",
    "    if model_type=='vgg19':\n",
    "        model = VGG19(num_classes, img_size=config['data']['img_size'],)\n",
    "    if model_type=='ViT':\n",
    "        model = VisionTransformer(num_classes=num_classes, img_size=config['data']['img_size'])\n",
    "    if model_type=='EfficientNet':\n",
    "        model = tf.keras.applications.EfficientNetB7(classes=num_classes, weights=None,\n",
    "                                                     input_shape=(config['data']['img_size'], config['data']['img_size'], 3))\n",
    "    aug_model = aug_process(config['data']['img_size'])\n",
    "    \n",
    "    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def calc_loss(target_y, predicted_y):\n",
    "        return tf.math.reduce_mean(loss_obj(target_y, predicted_y))\n",
    "    \n",
    "    acc_func = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    def calc_acc(target_y, predicted_y):\n",
    "        return tf.math.reduce_mean(acc_func(target_y, predicted_y))\n",
    "    \n",
    "optimizer = tfa.optimizers.RectifiedAdam(lr=1e-3, clipnorm=0.01)\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "#model.compile(optimizer=opt,\n",
    "#              loss='sparse_categorical_crossentropy', metrics=['acc'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-agency",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "turkish-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch like learning rate scheduler\n",
    "class ReduceLROnPlateau():\n",
    "    def __init__(self, optimizer, patience, factor):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.best_loss = None\n",
    "        self.count = 0\n",
    "    def step(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif self.best_loss>loss:\n",
    "            self.count = 0\n",
    "            self.best_loss = loss\n",
    "        else:\n",
    "            self.count+=1\n",
    "            if self.count==self.patience:\n",
    "                self.optimizer.learning_rate = self.optimizer.learning_rate*self.factor\n",
    "                self.count=0\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_img, label, optimizer):\n",
    "    aug_img = aug_model(input_img)\n",
    "    with tf.GradientTape() as GT:\n",
    "        prediction = model(aug_img, training=True)\n",
    "        loss = calc_loss(label, prediction)\n",
    "        acc = calc_acc(label, prediction)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "    scaled_grad = GT.gradient(scaled_loss, model.trainable_variables)\n",
    "    grad = optimizer.get_unscaled_gradients(scaled_grad)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(input_img, label, optimizer):\n",
    "    per_replica_losses, per_replica_acc = strategy.run(train_step, args=(input_img, label, optimizer))\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
    "    acc = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_acc, axis=None)\n",
    "    return loss, acc\n",
    "\n",
    "@tf.function\n",
    "def val_step(input_img, label):\n",
    "    prediction = model(input_img)\n",
    "    loss = calc_loss(label, prediction)\n",
    "    acc = calc_acc(label, prediction)\n",
    "    return loss, acc\n",
    "\n",
    "@tf.function\n",
    "def distributed_val_step(input_img, label):\n",
    "    per_replica_losses, per_replica_acc = strategy.run(val_step, args=(input_img, label))\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
    "    acc = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_acc, axis=None)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consolidated-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.create_file_writer(f\"{log_dir}/train\")\n",
    "val_writer = tf.summary.create_file_writer(f\"{log_dir}/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convinced-appeal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 711 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 711 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "3 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[StatefulPartitionedCall/div_no_nan/ReadVariableOp_1/_48]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (2) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[truediv_1/_152]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_train_step_406679]\n\nFunction call stack:\ndistributed_train_step -> distributed_train_step -> distributed_train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8c56407622a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtmp_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtmp_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtmp_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtmp_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 3 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[StatefulPartitionedCall/div_no_nan/ReadVariableOp_1/_48]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (2) Resource exhausted:  OOM when allocating tensor with shape[512,32,128,128] and type half on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n\t [[{{node StatefulPartitionedCall/replica_1/efficientnetb7/block1b_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[truediv_1/_152]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_train_step_406679]\n\nFunction call stack:\ndistributed_train_step -> distributed_train_step -> distributed_train_step\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, patience=4, factor=0.95)\n",
    "\n",
    "for epoch in range(config['data']['epochs']):\n",
    "    \n",
    "    \n",
    "    #train\n",
    "    st = dt.datetime.now()\n",
    "    tmp_loss_list = []\n",
    "    tmp_acc_list = []\n",
    "    for inputs, outputs in train_ds:\n",
    "        tmp_loss, tmp_acc = distributed_train_step(inputs, outputs, optimizer)\n",
    "        tmp_loss_list.append(tmp_loss)\n",
    "        tmp_acc_list.append(tmp_acc)\n",
    "        \n",
    "    train_loss = tf.math.reduce_mean(tmp_loss_list).numpy()\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    train_acc = tf.math.reduce_mean(tmp_acc_list).numpy()\n",
    "    train_acc_list.append(train_acc)\n",
    "    \n",
    "    tmp_time = dt.datetime.now()-st\n",
    "    \n",
    "    \n",
    "    #validation\n",
    "    tmp_loss_list = []\n",
    "    tmp_acc_list = []\n",
    "    for inputs, outputs in val_ds:\n",
    "        tmp_loss, tmp_acc = distributed_val_step(inputs, outputs)\n",
    "        tmp_loss_list.append(tmp_loss)\n",
    "        tmp_acc_list.append(tmp_acc)\n",
    "        \n",
    "    val_loss = tf.math.reduce_mean(tmp_loss_list).numpy()\n",
    "    val_loss_list.append(val_loss)\n",
    "    \n",
    "    val_acc = tf.math.reduce_mean(tmp_acc_list).numpy()\n",
    "    val_acc_list.append(val_acc)\n",
    "    \n",
    "    str_time = str(tmp_time).split('.')[0]\n",
    "    learning_rate = optimizer.learning_rate.numpy()\n",
    "    \n",
    "    for writer, loss, acc in zip([train_writer, val_writer], \n",
    "                                 [train_loss, val_loss],\n",
    "                                 [train_acc, val_acc]):\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"loss\", loss, step=epoch)\n",
    "            tf.summary.scalar(\"acc\", acc, step=epoch)\n",
    "            writer.flush()\n",
    "    \n",
    "    print(f'epoch:{epoch+1} - train_loss:{train_loss:.7f} - val_loss:{val_loss:.7f} - time:{str_time} - leaning_rate:{learning_rate:.8f}')\n",
    "    \n",
    "    lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{output_path}/{model_type}.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "arbitrary-diary",
   "metadata": {},
   "source": [
    "TB = tf.keras.callbacks.TensorBoard(log_dir=f'{output_path}/logs/{file_name}',update_freq='batch',\n",
    "                                    histogram_freq=1, embeddings_freq=1)\n",
    "RLRP = tf.keras.callbacks.ReduceLROnPlateau(factor=0.95, patience=4)\n",
    "hist = model.fit(train_ds, validation_data=val_ds,\n",
    "                 epochs=config['data']['epochs'], callbacks=[TB, RLRP])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "likely-spencer",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-brazilian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
