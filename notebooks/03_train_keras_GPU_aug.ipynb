{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-inflation",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "from model.vgg19 import VGG19\n",
    "from model.ViT import VisionTransformer\n",
    "from model.augmentation import aug_process\n",
    "from model.augmentator import Augmentator\n",
    "from dataloader import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-johnson",
   "metadata": {},
   "source": [
    "# mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promising-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mixed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "whole-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From /home/a_imagawa/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "if is_mixed:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-ranch",
   "metadata": {},
   "source": [
    "# model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "international-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'EfficientNet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-candidate",
   "metadata": {},
   "source": [
    "# file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outdoor-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_open = open('../config.json', 'r')\n",
    "config = json.load(json_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "absolute-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'{config[\"filepath\"][\"dataset\"]}'\n",
    "partitions_path = f'{config[\"filepath\"][\"partitions\"]}'\n",
    "output_path = f'{config[\"filepath\"][\"output\"]}'\n",
    "file_name = f\"{model_type}_{config['data']['img_size']}_keras_GPU_aug\"\n",
    "log_dir = f\"{output_path}/logs/{file_name}\"\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "departmental-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_path_list = glob.glob(f\"{partitions_path}/Test*\")\n",
    "train_txt_path_list = glob.glob(f\"{partitions_path}/Train*\")\n",
    "class_name_path = f\"{partitions_path}/ClassName.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-newport",
   "metadata": {},
   "source": [
    "# label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virtual-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(class_name_path, 'r')\n",
    "label_name_list = f.readlines()\n",
    "label_name_list = list(map(lambda tmp_path: tmp_path[:-1].split('/', 2)[2], label_name_list))\n",
    "f.close()\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-branch",
   "metadata": {},
   "source": [
    "# text to path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaningful-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_path(txt_path_list):\n",
    "    path_list = []\n",
    "    for path in txt_path_list:\n",
    "        f = open(path, 'r')\n",
    "        path_list+=f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    path_list = list(map(lambda tmp_path: dataset_path+tmp_path[:-1], path_list))#.remove(config[\"data\"][\"exclude_list\"])\n",
    "    path_list = sorted(list(set(path_list)-set(config[\"data\"][\"exclude_list\"])))\n",
    "    label_list = list(map(lambda tmp_path: label_to_index[tmp_path.split('/', 6)[6].rsplit('/', 1)[0]], path_list))\n",
    "    return path_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unauthorized-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list, label_list = txt_to_path(train_txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "located-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path_list, val_img_path_list,\\\n",
    "train_label_list, val_label_list = train_test_split(img_path_list, label_list,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "test_img_path_list, test_label_list = txt_to_path(test_txt_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surprised-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataloader = dataloader(config['data']['batch_size'], config['data']['img_size'],)\n",
    "train_ds = tmp_dataloader(train_img_path_list, train_label_list, shuffle_buffer=100)\n",
    "val_ds = tmp_dataloader(val_img_path_list, val_label_list, is_train=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-reconstruction",
   "metadata": {},
   "source": [
    "# def model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "norwegian-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_classes = len(label_to_index)+1\n",
    "with strategy.scope():\n",
    "    if model_type=='vgg19':\n",
    "        tmp_model = VGG19(num_classes, img_size=config['data']['img_size'],)\n",
    "    if model_type=='ViT':\n",
    "        tmp_model = VisionTransformer(num_classes=num_classes, img_size=config['data']['img_size'])\n",
    "    if model_type=='EfficientNet':\n",
    "        tmp_model = tf.keras.applications.EfficientNetB3(classes=num_classes, weights=None,\n",
    "                                                     input_shape=(config['data']['img_size'], config['data']['img_size'], 3))\n",
    "    aug_model = aug_process(config['data']['img_size'])\n",
    "    model = Augmentator(tmp_model, aug_model)\n",
    "    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def calc_loss(target_y, predicted_y):\n",
    "        return tf.math.reduce_mean(loss_obj(target_y, predicted_y))\n",
    "    \n",
    "    acc_func = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    def calc_acc(target_y, predicted_y):\n",
    "        return tf.math.reduce_mean(acc_func(target_y, predicted_y))\n",
    "    \n",
    "optimizer = tfa.optimizers.RectifiedAdam(lr=config['data']['lr'], clipnorm=0.01)\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy', metrics=['acc'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-moderator",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "INFO:tensorflow:batch_all_reduce: 340 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 340 all-reduces with algorithm = nccl, num_packs = 1\n",
      "1002/1002 [==============================] - 562s 381ms/step - loss: 5.9696 - acc: 0.0056 - val_loss: 5.7826 - val_acc: 0.0175\n",
      "Epoch 2/8\n",
      "1002/1002 [==============================] - 371s 370ms/step - loss: 5.5115 - acc: 0.0168 - val_loss: 5.3510 - val_acc: 0.0273\n",
      "Epoch 3/8\n",
      "1002/1002 [==============================] - 372s 370ms/step - loss: 5.2039 - acc: 0.0304 - val_loss: 5.1022 - val_acc: 0.0387\n",
      "Epoch 4/8\n",
      "1002/1002 [==============================] - 373s 371ms/step - loss: 4.9594 - acc: 0.0466 - val_loss: 4.7074 - val_acc: 0.0658\n",
      "Epoch 5/8\n",
      "1002/1002 [==============================] - 371s 370ms/step - loss: 4.7587 - acc: 0.0631 - val_loss: 4.5391 - val_acc: 0.0809\n",
      "Epoch 6/8\n",
      "1002/1002 [==============================] - 372s 371ms/step - loss: 4.5913 - acc: 0.0784 - val_loss: 4.2829 - val_acc: 0.1076\n",
      "Epoch 7/8\n",
      "1002/1002 [==============================] - 372s 370ms/step - loss: 4.4732 - acc: 0.0905 - val_loss: 4.1526 - val_acc: 0.1204\n",
      "Epoch 8/8\n",
      " 940/1002 [===========================>..] - ETA: 20s - loss: 4.3501 - acc: 0.1039"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TB = tf.keras.callbacks.TensorBoard(log_dir=f'{output_path}/logs/{file_name}',\n",
    "                                    histogram_freq=1, embeddings_freq=1)\n",
    "RLRP = tf.keras.callbacks.ReduceLROnPlateau(factor=0.95, patience=2)\n",
    "hist = model.fit(train_ds, validation_data=val_ds,\n",
    "                 epochs=config['data']['epochs'], callbacks=[TB, RLRP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
